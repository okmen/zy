package com.egou.search.lucene;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.StringReader;
import java.util.ArrayList;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
//import org.apache.lucene.document.DoubleField;
//import org.apache.lucene.document.IntField;
//import org.apache.lucene.document.LongField;
import org.apache.lucene.document.StringField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.document.Field.Store;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TrackingIndexWriter;
import org.apache.lucene.search.BooleanClause.Occur;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.ControlledRealTimeReopenThread;
//import org.apache.lucene.search.FieldCache;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.NumericRangeQuery;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ReferenceManager;
import org.apache.lucene.search.ScoreDoc;
//import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.SearcherFactory;
import org.apache.lucene.search.SearcherManager;
import org.apache.lucene.search.Sort;
import org.apache.lucene.search.SortField;
//import org.apache.lucene.search.Sort;
//import org.apache.lucene.search.SortField;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
//import org.apache.lucene.search.TopScoreDocCollector;
import org.apache.lucene.search.WildcardQuery;
//import org.apache.lucene.search.highlight.Formatter;
//import org.apache.lucene.search.highlight.Fragmenter;
//import org.apache.lucene.search.highlight.Highlighter;
//import org.apache.lucene.search.highlight.InvalidTokenOffsetsException;
//import org.apache.lucene.search.highlight.QueryScorer;
//import org.apache.lucene.search.highlight.SimpleHTMLFormatter;
//import org.apache.lucene.search.highlight.SimpleSpanFragmenter;
import org.apache.lucene.store.Directory;
import org.apache.lucene.util.Version;
//import org.springframework.beans.factory.annotation.Autowired;
import org.wltea.analyzer.core.IKSegmenter;
import org.wltea.analyzer.core.Lexeme;










//import com.egou.search.service.ILuceneSerive;
import com.egou.search.vo.ProductIndex;
import com.egou.utils.DateUtils;
import com.egou.utils.ParseHelper;

public class NearRealTimeSearch {
	private static Version Lucene_Version = Version.LUCENE_4_10_4;



	//索引位置
	private Directory directory = null;
	//
	private IndexWriter writer = null;
	//索引读取
	private IndexReader reader;
	/** nrt init **/
	private TrackingIndexWriter trackingIndexWriter = null;
	private ReferenceManager<IndexSearcher> reMgr = null;// 绫讳技浜嶭ucene3.x涓殑NrtManager
	private ControlledRealTimeReopenThread<IndexSearcher> crt = null;
	private Log logger = LogFactory.getLog(this.getClass());
	private String stopWordTable = "";
	private Set<String> stopWordSet = null;

	// 
	public NearRealTimeSearch() {}

	public void initStopWord() {
		try {
			// 读入停用词文件
			BufferedReader StopWordFileBr = new BufferedReader(new InputStreamReader(new FileInputStream(new File(stopWordTable))));
			// 用来存放停用词的集合
			stopWordSet = new HashSet<String>();
			// 初如化停用词集
			String stopWord = null;
			for (; (stopWord = StopWordFileBr.readLine()) != null;) {
				stopWordSet.add(stopWord);
			}
			// 关闭流
			StopWordFileBr.close();
		} catch (Exception ex) {

		}
	}

	public void init() {
		if (crt == null) {
			try {
				initStopWord();
				stopWordTable = getClass().getClassLoader().getResource("ChineseStopWord.txt").getPath();
				directory = new FileIndexUtils().getDirectory();
				if (IndexWriter.isLocked(directory)) {
					IndexWriter.unlock(directory);
				}
				// Analyzer analyzer=new StandardAnalyzer(Version.LUCENE_46);
				writer = new IndexWriter(directory, new IndexWriterConfig(Lucene_Version, AnalyzerUtil.getIkAnalyzer()));
				trackingIndexWriter = new TrackingIndexWriter(writer);
				reMgr = new SearcherManager(writer, true, new SearcherFactory());
				/** 在0.025s~5.0s之间重启一次线程，这个是时间的最佳实践 **/
				crt = new ControlledRealTimeReopenThread<>(trackingIndexWriter, reMgr, 5.0, 0.025);
				crt.setDaemon(true);// 设置为后台服务
				crt.setName("Index update to disk");// 线程名称
				crt.start();// 线程启动

			} catch (Exception e) {
				System.out.println("Lucene初始化失败：" + e.getMessage());
				e.printStackTrace();
			}
		}
	}

	/**
	 * 定期提交内存中得索引到硬盘上，防止丢失
	 */
	public void commit() {
		try {
			writer.commit();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	/**
	 * 建立索引 要实现search nrt,需要使用TrackIndexWriter保存document，同时Writer也不需要关闭。
	 * 
	 * **/
	public void index(List<ProductIndex> ids) throws IOException {

		try {
			if (ids == null || ids.size() <= 0)
				return;
			for (int i = 0; i < ids.size(); i++) {
				Document doc = new Document();
				ProductIndex ldata = ids.get(i);
				try {
					doc.add(new StringField("id", ldata.getProductid().toString(), Store.YES));
					doc.add(new TextField("title", ldata.getTitle(), Store.YES));
					
					if (trackingIndexWriter == null) {
						// logger.warn("Lucene创建索引时异常，trackingIndexWriter为空");
						System.out.println("Lucene创建索引时异常，trackingIndexWriter为空");
						init();
					}
					trackingIndexWriter.addDocument(doc);
				} catch (Exception ex) {
					// logger.error("Lucene创建索引时异常:" + ex.getMessage());
					System.out.println("Lucene创建索引时异常:" + ex.getMessage());
					continue;
				}
			}
		} finally {
			commit();// 首次创建，提交索引,只有提交后，才会在索引片段中也将信息改变
		}
	}

	/*** 鏌ヨ 
	 * @throws IOException **/
	public void query() throws IOException {
		IndexSearcher is = getSearcher();
		try {
			// 閫氳繃reader鍙互鏈夋晥鐨勮幏鍙栧埌鏂囨。鐨勬暟閲�
			System.out.println("numDocs:" + is.getIndexReader().numDocs());
			System.out.println("maxDocs:" + is.getIndexReader().maxDoc());
			System.out.println("deleteDocs:" + is.getIndexReader().numDeletedDocs());
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				reMgr.release(is);
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
	}

	/**
	 * 鍒犻櫎 浣跨敤trackIndexWriter杩涜鏁版嵁鍒犻櫎锛屼篃涓嶉渶瑕佸叧闂璚riter
	 * **/
	public void delete(String productid) {
		try {

			trackingIndexWriter.deleteDocuments(new Term("id", productid));
		} catch (Exception e) {
			logger.error("Lucene鍒犻櫎绱㈠紩鏃跺紓甯�:" + e.getMessage());
			e.printStackTrace();
		}
	}

	/**
	 * 淇敼 浣跨敤trackIndexWriter杩涜淇敼锛屼笉闇�瑕佸叧闂瓀riter
	 * **/
	public void update(ProductIndex ldata) {
		try {
			Document doc = new Document();
			/*
			 * Lucene骞舵病鏈夋彁渚涙洿鏂帮紝杩欓噷鐨勬洿鏂版搷浣滃叾瀹炴槸濡備笅涓や釜鎿嶄綔鐨勫悎闆� 鍏堝垹闄や箣鍚庡啀娣诲姞
			 */
			doc.add(new StringField("id", ldata.getProductid().toString(), Store.YES)); // productid
			doc.add(new TextField("content", ldata.getTitle(), Store.YES)); // 浜у搧鏍囬

			trackingIndexWriter.updateDocument(new Term("id", ldata.getProductid().toString()), doc);
		} catch (Exception e) {
			logger.error("Lucene鏇存柊绱㈠紩鏃跺紓甯�:" + e.getMessage());
			e.printStackTrace();
		}
	}

	

	/**  创建索引查询 IndexSearch 
	 * @throws IOException **/
	public IndexSearcher getSearcher() throws IOException { 
		if(directory==null)
			directory = new FileIndexUtils().getDirectory();
		reader = DirectoryReader.open(directory);//读取目录 
		IndexSearcher is = new IndexSearcher(reader);;
		return is;
	}

	/**
	 * 
	 */
//	public void close() {
//		crt.interrupt();
//		crt.close();
//		try {
//			writer.commit();
//			writer.close();
//
//		} catch (IOException e) {
//			e.printStackTrace();
//		}
//	}

	public List<ProductIndex> search(String text ,int pageIndex,int pageSize) throws IOException {
		IndexSearcher is = getSearcher();
		BooleanQuery booleanquery = new BooleanQuery();
		BooleanQuery hitQuery = new BooleanQuery();

		if (stopWordSet == null || stopWordSet.size() <= 0)
			initStopWord();
		// 创建分词对象
		StringReader sr = new StringReader(text);
		
		if (text.length() > 0) {
			IKSegmenter ik = new IKSegmenter(sr, false);
			Lexeme lex = null;
			Query squery = new TermQuery(new Term("title", text));
			hitQuery.add(squery, Occur.SHOULD);
			squery.setBoost(1000000.0f);
			booleanquery.add(squery, Occur.SHOULD);
			lex = ik.next();
			while (lex != null) { 
				// 去除停用词
				if (stopWordSet.contains(lex.getLexemeText())) {
					continue;
				}
				Query likequery = new TermQuery(new Term("title", lex.getLexemeText()));
				hitQuery.add(likequery, Occur.SHOULD);
				if (!text.equals(lex.getLexemeText()))
					likequery.setBoost(0.0f);
				booleanquery.add(likequery, Occur.SHOULD);
			}
		} else {
			Query likequery = new WildcardQuery(new Term("title", "*"));
			booleanquery.add(likequery, Occur.MUST);
		}
		SortField sortf = new SortField("id", SortField.Type.INT, true);
		Sort sort = new Sort(new SortField[] { new SortField(null, SortField.Type.SCORE, false), sortf });
		TopDocs topDocs = is.search(booleanquery, 2000000, sort); // 搜索相似度最高的N条记录
		ScoreDoc[] docs = topDocs.scoreDocs;
		// is.search(booleanquery, topCollector);
		// 查询结果的总数量
		// int totalNum = topCollector.getTotalHits();
		int totalNum = topDocs.totalHits;
		int begin = pageSize * (pageIndex - 1);
		int end = Math.min(begin + pageSize, docs.length);
		
		List<ProductIndex> resultList=new ArrayList<ProductIndex>();
		for (int i = begin; i < end; i++) {
			ScoreDoc scdoc = docs[i];
			Document document = is.doc(scdoc.doc);
			ProductIndex index=new ProductIndex();
			index.setProductid(ParseHelper.toLong(document.get("id")));
			index.setTitle(document.get("title"));
//			index.setTitle(document.get("createtime"));
			resultList.add(index);
		}
		try {
			reader.close();//关闭资源    
	        directory.close();//关闭连接 
		} catch (IOException e) {
			e.printStackTrace();
		}
		return resultList;
	}

}
